{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0d38c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import Omniglot\n",
    "from torchvision import transforms\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9369ac85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/brendenlake/omniglot/master/python/images_background.zip to ./data/omniglot-py/images_background.zip\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b729b17e96534ba5ab8a1dcc1f1faab6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9464212 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/omniglot-py/images_background.zip to ./data/omniglot-py\n"
     ]
    }
   ],
   "source": [
    "normalize = transforms.Normalize(mean=[0.92206, 0.92206, 0.92206],\n",
    "                                         std=[0.08426, 0.08426, 0.08426])\n",
    "transform = transforms.Compose([transforms.ToTensor(), normalize])\n",
    "omni = Omniglot(root='./data/', transform=transform, background=True, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfe6692",
   "metadata": {},
   "outputs": [],
   "source": [
    "omni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec10ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "None\n",
      "> \u001b[0;32m/var/folders/gh/3pd23sd51hn2p7774mv2zt4r0000gn/T/ipykernel_10742/432578238.py\u001b[0m(131)\u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    129 \u001b[0;31m    \u001b[0momni\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOmniglot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./data/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackground\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    130 \u001b[0;31m    \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 131 \u001b[0;31m    \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStochasticOmniSetData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0momni\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_set_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    132 \u001b[0;31m    \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStochasticOmniSetData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0momni\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_set_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    133 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> r\n",
      "first time train loader\n",
      "--Return--\n",
      "None\n",
      "> \u001b[0;32m/var/folders/gh/3pd23sd51hn2p7774mv2zt4r0000gn/T/ipykernel_10742/432578238.py\u001b[0m(146)\u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    144 \u001b[0;31m    \u001b[0mseen_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    145 \u001b[0;31m    \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'first time train loader'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 146 \u001b[0;31m    \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    147 \u001b[0;31m        \u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0may\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    148 \u001b[0;31m        \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> 5\n",
      "5\n",
      "ipdb> 4\n",
      "4\n",
      "ipdb> 3\n",
      "3\n",
      "ipdb> 2\n",
      "2\n",
      "ipdb> 1\n",
      "1\n",
      "ipdb> 6\n",
      "6\n",
      "ipdb> 5\n",
      "5\n",
      "ipdb> 7\n",
      "7\n",
      "ipdb> 3\n",
      "3\n",
      "ipdb> 4\n",
      "4\n",
      "ipdb> 5\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "import pdb\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn\n",
    "from torch.utils.data import Dataset, DataLoader, BatchSampler, SequentialSampler\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import Omniglot\n",
    "\n",
    "class StochasticOmniSetData(Dataset):\n",
    "    def __init__(self, omni, epoch_len, max_set_length=10, min_set_length=6):\n",
    "        self.omni = omni\n",
    "        self._len = epoch_len # number of set samples in an epoch\n",
    "        self.max_set_length = max_set_length\n",
    "        self.min_set_length = min_set_length\n",
    "        self.probs = {n: np.ones(n) / n for n in range(1, max_set_length + 1)}\n",
    "        self.labels = np.array([t[1] for t in omni._flat_character_images])\n",
    "        self.unique_chars = len(set(self.labels))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._len\n",
    "\n",
    "    def __getitem__(self, bidx):\n",
    "        batch_size = len(bidx)\n",
    "        set_length = np.random.randint(self.min_set_length, self.max_set_length + 1)\n",
    "        unique_nums = np.random.randint(1,(set_length+1), batch_size)\n",
    "        vals = np.zeros((batch_size, set_length), dtype=int)\n",
    "\n",
    "        for j in range(batch_size):\n",
    "            unique_num = unique_nums[j]\n",
    "            char_list = np.random.choice(self.unique_chars, unique_num, replace=False)\n",
    "            how_many = 1 + np.random.multinomial(set_length - unique_num, self.probs[unique_num])\n",
    "            indices = []\n",
    "\n",
    "            for i in range(len(char_list)):\n",
    "                label_eq = np.where(self.labels==char_list[i])[0]\n",
    "                choice = np.random.choice(len(label_eq), how_many[i],replace=False)\n",
    "                index = list(label_eq[choice])\n",
    "                indices += (index)\n",
    "\n",
    "            indices = np.array(indices)\n",
    "            vals[j] = indices\n",
    "            # grab the images\n",
    "        vals_unrolled = vals.reshape(-1)\n",
    "        imgs = torch.stack([self.omni[i][0] for i in vals_unrolled])\n",
    "        imgs = imgs.view(len(bidx), -1, 105, 105)\n",
    "        return imgs, unique_nums\n",
    "        #train_inds.append(vals)\n",
    "        #train_labels.append(np.array(label_set))\n",
    "        #return train_inds, train_labels\n",
    "\n",
    "class OmniSetData(Dataset):\n",
    "    def __init__(self, data, targets, omni):\n",
    "        '''\n",
    "        data: dict from seq len -> tensor\n",
    "        target: dict from seq len -> tensor\n",
    "        imgs: numpy array of images\n",
    "        '''\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "        self.omni = omni\n",
    "        self._len = sum([len(x) for x in data.values()])\n",
    "        self._min_set_len = min(data.keys())\n",
    "        self._lens = sorted(data.keys())\n",
    "        self._total_each = data[self._min_set_len].shape[0]\n",
    "        self._img_h = omni[0][0].shape[1]\n",
    "        self._img_w = omni[0][0].shape[2]\n",
    "\n",
    "    @staticmethod\n",
    "    def from_files(idx_pkl, tgt_pkl, omni, fraction=1):\n",
    "        xmaps = {}\n",
    "        ymaps = {}\n",
    "        xs = pickle.load(open(idx_pkl, 'rb'))\n",
    "        ys = pickle.load(open(tgt_pkl, 'rb'))\n",
    "\n",
    "        for x, y in zip(xs, ys):\n",
    "            n = x.shape[1]\n",
    "            if n not in xmaps:\n",
    "                xmaps[n] = []\n",
    "                ymaps[n] = []\n",
    "            frac_len = int(len(x) * fraction)\n",
    "            xmaps[n].append(x[:frac_len])\n",
    "            ymaps[n].append(y[:frac_len])\n",
    "\n",
    "        flattened_xs = {n: np.vstack(xmaps[n]) for n in xmaps.keys()}\n",
    "        flattened_ys = {n: np.concatenate(ymaps[n]) for n in ymaps.keys()}\n",
    "        return OmniSetData(flattened_xs, flattened_ys, omni)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._len\n",
    "\n",
    "    def __getitem__(self, bidx):\n",
    "        seq_len = self._min_set_len + (bidx[0] % len(self._lens))\n",
    "        new_bidx = [b % self._total_each for b in bidx]\n",
    "        idxs = self.data[seq_len][new_bidx]\n",
    "        idxs_unrolled = idxs.reshape(-1)\n",
    "        bimgs = torch.stack([self.omni[i][0] for i in idxs_unrolled])\n",
    "        bimgs = bimgs.reshape(len(new_bidx), -1, self._img_h, self._img_w)\n",
    "        return bimgs, self.targets[seq_len][new_bidx]\n",
    "\n",
    "\n",
    "# DEPRECATED\n",
    "class SetDataset(Dataset):\n",
    "    def __init__(self, dataset, set_size):\n",
    "        self.dataset = dataset\n",
    "        self.set_size = set_size\n",
    "        self.samples = torch.randint(0, len(self.dataset),\n",
    "                                     size=(len(self.dataset), set_size))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.samples[idx]\n",
    "        vals = [self.dataset[x] for x in sample]\n",
    "        ys = torch.tensor([v[1] for v in vals])\n",
    "        xs = [v[0] for v in vals]\n",
    "        xs = torch.stack(xs)\n",
    "        nuniques = len(set(vals))\n",
    "        return xs, nuniques\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    epoch_len = 3\n",
    "    bs = 3\n",
    "    max_set_length = 2\n",
    "    normalize = transforms.Normalize(mean=[0.92206, 0.92206, 0.92206],\n",
    "                                         std=[0.08426, 0.08426, 0.08426])\n",
    "    transform = transforms.Compose([transforms.ToTensor(), normalize])\n",
    "    omni = Omniglot(root='./data/', transform=transform, background=True, download=True)\n",
    "    pdb.set_trace()\n",
    "    train_dataset = StochasticOmniSetData(omni, epoch_len, max_set_length)\n",
    "    test_dataset = StochasticOmniSetData(omni, epoch_len, max_set_length)\n",
    "\n",
    "    train_dataloader = DataLoader(dataset=train_dataset,\n",
    "        sampler=BatchSampler(\n",
    "            SequentialSampler(train_dataset), batch_size=bs, drop_last=False\n",
    "        ),\n",
    "    )\n",
    "    test_dataloader = DataLoader(dataset=test_dataset,\n",
    "        sampler=BatchSampler(\n",
    "            SequentialSampler(test_dataset), batch_size=bs, drop_last=False\n",
    "        ),\n",
    "    )\n",
    "    seen_vals = {}\n",
    "    print('first time train loader')\n",
    "    for idx, batch in enumerate(train_dataloader):\n",
    "        ax, ay, az = batch\n",
    "        ax = ax[0]\n",
    "        ay = ay[0]\n",
    "        az = az[0]\n",
    "        print(ay, az)\n",
    "        seen_vals.update(az.tolist())\n",
    "\n",
    "    other = {}\n",
    "    print('rerunning train loader')\n",
    "    for idx, batch in enumerate(train_dataloader):\n",
    "        ax, ay, az = batch\n",
    "        ax = ax[0]\n",
    "        ay = ay[0]\n",
    "        az = az[0]\n",
    "        print(ay, az)\n",
    "        other.update(az.tolist())\n",
    "\n",
    "    lst = {}\n",
    "    print('running test loader')\n",
    "    for batch in test_dataloader:\n",
    "        ax, ay, az = batch\n",
    "        ax = ax[0]\n",
    "        ay = ay[0]\n",
    "        az = az[0]\n",
    "        print(ay, az)\n",
    "        lst.update(az.tolist())\n",
    "    pdb.set_trace()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149f3508",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
