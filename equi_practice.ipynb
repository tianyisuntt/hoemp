{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f8013435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".CodeMirror{\n",
       "font-size: 11px;\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style type='text/css'>\n",
    ".CodeMirror{\n",
    "font-size: 11px;\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bb755183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "torch.Size([3, 2, 5, 5])\n",
      "torch.Size([2, 5, 5])\n",
      "torch.Size([5, 5])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np \n",
    "\n",
    "inputs = torch.FloatTensor(3, 2, 5, 5)\n",
    "print(len(inputs))\n",
    "print(inputs.shape)\n",
    "print(inputs[0].shape)\n",
    "print(inputs[0][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ae5b28fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ops_2_to_2(inputs, normalize = False):\n",
    "    \"\"\"\n",
    "    Construct the 15 broadcast tensors for a 2 -> 2 equivariant layer \n",
    "    \"\"\"\n",
    "    N, D, m, m = inputs.shape\n",
    "    dim = inputs.shape[-1]\n",
    "    \n",
    "    # summation tensors \n",
    "    diag_part = torch.diagonal(inputs, dim1=-2, dim2=-1) # N x D x m\n",
    "    sum_diag_part = diag_part.sum(dim=2, keepdims=True) # N x D x 1\n",
    "    sum_rows = inputs.sum(dim=3) # N x D x m\n",
    "    sum_cols = inputs.sum(dim=2) # N x D x m\n",
    "    sum_all = inputs.sum(dim=(2,3)) # N x D\n",
    "    \n",
    "    # broadcast the summation tensors\n",
    "    ops = [None]*(15+1)\n",
    "    ops[1] = torch.diag_embed(diag_part) # N x D x m x m \n",
    "    # dim = 2\n",
    "    ops[2] = torch.diag_embed(sum_diag_part.tile(-1, -1, dim))\n",
    "    ops[3] = torch.diag_embed(sum_rows)\n",
    "    ops[4] = torch.diag_embed(sum_cols)\n",
    "    ops[5] = torch.diag_embed(sum_all.unsqueeze(-1).tile(-1,-1,dim ))\n",
    "    ops[6] = sum_cols.unsqueeze(3).tile(-1, -1, -1, dim)\n",
    "    ops[7] = sum_rows.unsqueeze(3).tile(-1, -1, -1, dim)\n",
    "    ops[8] = sum_cols.unsqueeze(2).tile(-1, -1, dim, -1)\n",
    "    ops[9] = sum_rows.unsqueeze(2).tile(-1, -1, dim, -1)\n",
    "    ops[10] = inputs\n",
    "    ops[11] = torch.transpose(inputs, 2, 3)\n",
    "    ops[12] = diag_part.unsqueeze(3).tile(-1, -1, -1, dim)\n",
    "    ops[13] = diag_part.unsqueeze(2).tile(-1, -1, dim, -1)\n",
    "    ops[14] = sum_diag_part.unsqueeze(3).tile(-1, -1, dim, dim)\n",
    "    ops[15] = sum_all.unsqueeze(-1).unsqueeze(-1).tile(-1, -1, dim, dim)\n",
    "    \n",
    "    return torch.stack(ops[1:], dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6b8c5c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ops_3_to_3(inputs):\n",
    "    \"\"\"\n",
    "    Construct a minimal subset (20) of the 3 -> 3 broadcast tensors\n",
    "    \"\"\"\n",
    "    N, D, m, m, m = inputs.shape\n",
    "    # Summation tensors\n",
    "    sum_all = inputs.sum(dim=(-1, -2, -3))\n",
    "    sum_c1 = inputs.sum(dim=-1)\n",
    "    sum_c2 = inputs.sum(dim=-2)\n",
    "    sum_c3 = inputs.sum(dim=-3)\n",
    "    sum_c12 = inputs.sum(dim=(-1, -2))\n",
    "    sum_c13 = inputs.sum(dim=(-1, -3))\n",
    "    sum_c23 = inputs.sum(dim=(-2, -3))\n",
    "    # Broadcast the summation tensors\n",
    "    ops = [None] * 20\n",
    "    ops[1] = sum_all.view(N, D, 1, 1, 1).expand(-1, -1, dim, dim, dim) / (m * m * m)\n",
    "    ops[2]  = sum_c1.unsqueeze(-1).expand(-1, -1, -1, -1, m) / m\n",
    "    ops[3]  = sum_c1.unsqueeze(-2).expand(-1, -1, -1, m, -1) / m\n",
    "    ops[4]  = sum_c1.unsqueeze(-3).expand(-1, -1, m, -1, -1) / m\n",
    "    ops[5]  = sum_c2.unsqueeze(-1).expand(-1, -1, -1, -1, m) / m\n",
    "    ops[6]  = sum_c2.unsqueeze(-2).expand(-1, -1, -1, m, -1) / m\n",
    "    ops[7]  = sum_c2.unsqueeze(-3).expand(-1, -1, m, -1, -1) / m\n",
    "    ops[8]  = sum_c3.unsqueeze(-1).expand(-1, -1, -1, -1, m) / m\n",
    "    ops[9]  = sum_c3.unsqueeze(-2).expand(-1, -1, -1, m, -1) / m\n",
    "    ops[10] = sum_c3.unsqueeze(-3).expand(-1, -1, m, -1, -1) / m\n",
    "    ops[11] = sum_c12.view(N, D, m, 1, 1).expand(-1, -1, -1, m, m) / (m*m)\n",
    "    ops[12] = sum_c12.view(N, D, 1, m, 1).expand(-1, -1, m, -1, m) / (m*m)\n",
    "    ops[13] = sum_c12.view(N, D, 1, 1, m).expand(-1, -1, m, m, -1) / (m*m)\n",
    "    ops[14] = sum_c13.view(N, D, m, 1, 1).expand(-1, -1, -1, m, m) / (m*m)\n",
    "    ops[15] = sum_c13.view(N, D, 1, m, 1).expand(-1, -1, m, -1, m) / (m*m)\n",
    "    ops[16] = sum_c13.view(N, D, 1, 1, m).expand(-1, -1, m, m, -1) / (m*m)\n",
    "    ops[17] = sum_c23.view(N, D, m, 1, 1).expand(-1, -1, -1, m, m) / (m*m)\n",
    "    ops[18] = sum_c23.view(N, D, 1, m, 1).expand(-1, -1, m, -1, m) / (m*m)\n",
    "    ops[19] = sum_c23.view(N, D, 1, 1, m).expand(-1, -1, m, m, -1) / (m*m)\n",
    "    return torch.stack(ops[1:], dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cd8c5e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "57b34ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Eq2to2(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super(Eq2to2, self).__init__()\n",
    "        self.basis = 15 # Bell(2+2) = 15\n",
    "        self.out_dim = out_dim\n",
    "        self.in_dim = in_dim\n",
    "        self.coefs = nn.Parameter(torch.zeros(in_dim, out_dim, self.basis))\n",
    "        self.bias = nn.Parameter(torch.zeros(1, out_dim, 1, 1))\n",
    "    def forward(self, inputs):\n",
    "        ops = ops_2_to_2(inputs)\n",
    "        output = torch.einsum('dsb,ndbij->nsij', self.coefs, ops)\n",
    "        output = output + self.bias\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9c78f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa639fbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb654e09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d91bd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6b3955f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 5, 5])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3f923ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag_part = torch.diagonal(inputs, dim1=-2, dim2=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a9aa5e04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 5])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diag_part.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
