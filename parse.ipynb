{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8004c449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".CodeMirror{\n",
       "font-size: 11px;\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style type='text/css'>\n",
    ".CodeMirror{\n",
    "font-size: 11px;\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50523044",
   "metadata": {},
   "source": [
    ".pkl to .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a74c9adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pdb\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "def ncols(page):\n",
    "    max_cols = 0\n",
    "    for _, row in page.iterrows():\n",
    "        ncols = len(row[~pd.isna(row)])\n",
    "        max_cols = max(max_cols, ncols)\n",
    "    return ncols\n",
    "\n",
    "def get_max_cols(lst):\n",
    "    return max([ncols(page) for page in tqdm(lst)])\n",
    "\n",
    "def parse_doses(row):\n",
    "    '''\n",
    "    Return dict mapping drug -> doseage\n",
    "    '''\n",
    "    def canonical_str(col, doses_dict):\n",
    "        '''\n",
    "        Col name: {DRUG}+{DRUG}+...+{DRUG}\n",
    "        Return: {DRUG}{DOSE}{DRUG}{DOSE}...\n",
    "        '''\n",
    "        parts = col.split('+')\n",
    "        return '-'.join([p + str(doses_dict[p]) for p in parts])\n",
    "\n",
    "    doses = {}\n",
    "    s = row[0]\n",
    "    parts = [s[i:i+4] for i in range(0, len(s), 4)]\n",
    "\n",
    "    for p in parts:\n",
    "        doses[p[:3]] = int(p[-1])\n",
    "\n",
    "    cols = []\n",
    "    for cstr in row[1:]:\n",
    "        if type(cstr) == str:\n",
    "            for c in cstr.split(' '):\n",
    "                cols.append(canonical_str(c, doses))\n",
    "        else:\n",
    "            continue\n",
    "    assert len(cols) == 31\n",
    "    return cols\n",
    "\n",
    "def clean_row(row):\n",
    "    values = []\n",
    "    for v in row.values:\n",
    "        if type(v) == str:\n",
    "            for vs in v.split(' '):\n",
    "                try:\n",
    "                    values.append(float(vs))\n",
    "                except:\n",
    "                    if 'TMP' in vs:\n",
    "                        values.append(float(vs[:6]))\n",
    "                    else:\n",
    "                        print(f\"Cant split string in clean row at page {pid}, row {i}\")\n",
    "                        pdb.set_trace()\n",
    "        else:\n",
    "            if not pd.isna(v):\n",
    "                values.append(v)\n",
    "    return np.array(values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48175e85",
   "metadata": {},
   "source": [
    "Comments:\n",
    "\n",
    "The `.isalpha()` method returns True if all the characters are alphabet letters (a-z)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a439580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print('efvr'.isalpha())\n",
    "print('e4fvr'.isalpha())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "872f13de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(lst):\n",
    "    '''\n",
    "    page: DataFrame of current page\n",
    "    prev_page: previous page\n",
    "    '''\n",
    "    # loop over a page\n",
    "    cols = None\n",
    "    index = []\n",
    "    batched_values = []\n",
    "    col_vals = []\n",
    "\n",
    "    for pid, pg in tqdm(enumerate(lst)):\n",
    "        #if len(pg) <= 3: \n",
    "        #    pass\n",
    "        print(\"page #:\", pid+1)\n",
    "        #print(pg)\n",
    "        # need access to last true row of lst\n",
    "        for i, row in pg.iterrows():\n",
    "            print(i)\n",
    "            #print(\"row index of the dataframe:\", i)\n",
    "            cleaned_row = row[~pd.isna(row)]\n",
    "            try:\n",
    "                if (type(cleaned_row.values[0]) != float) and cleaned_row.values[0][0].isalpha(): # start of a label row\n",
    "                    x = 22\n",
    "            except:\n",
    "                print(f\"Cant parse doses at page {pid}, row {i}\")\n",
    "                pdb.set_trace() # setting breakpoints and single stepping at the source line level for debugging.\n",
    "            if (type(cleaned_row.values[0]) != float) and cleaned_row.values[0][0].isalpha(): # start of a label row\n",
    "                # evict an l thing \n",
    "                if len(col_vals) > 0:\n",
    "                    #print(\"col_vals: \", len(col_vals))\n",
    "                    #print(\"COlS: ---\", cols) # label row\n",
    "                    if cols != None:\n",
    "                        #print(len(cols))\n",
    "                        index.extend(cols)\n",
    "                    batch = np.stack(col_vals).T\n",
    "                    #print(\"batch shape: \",batch.shape)\n",
    "                    assert batch.shape[0] == 31, \"Incorrect batch shape! {}\".format(batch.shape)\n",
    "                    res = np.zeros((batch.shape[0], 5))\n",
    "                    #print(\"res : \",res.shape)\n",
    "                    #print(\"batch: \", batch.shape)\n",
    "                    if batch.shape[1]>5: \n",
    "                        batch = batch.T[-3:].T\n",
    "                        print(\"pass!!\")\n",
    "                    res[:, :batch.shape[1]] = batch\n",
    "                    batched_values.append(res)\n",
    "                    #batched_values.append(batch)\n",
    "                    col_vals = []\n",
    "\n",
    "                try:\n",
    "                    cols = parse_doses(cleaned_row)\n",
    "                except:\n",
    "                    print(f\"Cant parse doses at page {pid}, row {i}\")\n",
    "                    pdb.set_trace()\n",
    "            else:\n",
    "                try:\n",
    "                    col_vals.append(clean_row(cleaned_row)) #cleaned_row.values.astype(float))\n",
    "                except:\n",
    "                    print(f\"Cant clean row at page {pid}, row {i}\")\n",
    "                    pdb.set_trace()\n",
    "\n",
    "    if len(col_vals) > 0:\n",
    "            index.extend(cols)\n",
    "            batch = np.stack(col_vals).T\n",
    "            assert (batch.shape[0] == 31), \"Incorrect batch shape!\"\n",
    "            res = np.zeros((batch.shape[0], 5))\n",
    "            res[:, :batch.shape[1]] = batch\n",
    "            batched_values.append(res)\n",
    "            col_vals = []\n",
    "\n",
    "    values = np.vstack(batched_values)\n",
    "    #print(type(index))\n",
    "    \n",
    "    aprox_missing = abs(values.shape[0]-len(index))\n",
    "    #print(index[-aprox_missing:])\n",
    "    index.extend(index[-aprox_missing:])\n",
    "    df = pd.DataFrame(values, index=index)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7c5d1ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 15.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page #: 1\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (1209, 5), indices imply (2418, 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/gh/3pd23sd51hn2p7774mv2zt4r0000gn/T/ipykernel_6604/1411222683.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m    \u001b[0mparsed_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./drug_add_291.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m    \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/gh/3pd23sd51hn2p7774mv2zt4r0000gn/T/ipykernel_6604/1411222683.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m    \u001b[0mlst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m291\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m292\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m    \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m    \u001b[0mparsed_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m    \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m    \u001b[0mparsed_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./drug_add_291.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/gh/3pd23sd51hn2p7774mv2zt4r0000gn/T/ipykernel_6604/1582479442.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(lst)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;31m#print(index[-aprox_missing:])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0maprox_missing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    692\u001b[0m                 )\n\u001b[1;32m    693\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m                 mgr = ndarray_to_mgr(\n\u001b[0m\u001b[1;32m    695\u001b[0m                     \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m                     \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mndarray_to_mgr\u001b[0;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[1;32m    349\u001b[0m     )\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m     \u001b[0m_check_values_indices_shape_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"array\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_check_values_indices_shape_match\u001b[0;34m(values, index, columns)\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0mpassed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0mimplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Shape of passed values is {passed}, indices imply {implied}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shape of passed values is (1209, 5), indices imply (2418, 5)"
     ]
    }
   ],
   "source": [
    " def main():\n",
    "    f = open('./area_pdf.pkl', 'rb')\n",
    "    #f = open('./small.pkl', 'rb')    \n",
    "    lst = pickle.load(f)\n",
    "    print(len(lst))\n",
    "    #lst = lst[:170] + lst[171] \n",
    "    #lst = lst[173:227]\n",
    "    #lst = lst[228:290]\n",
    "    lst = lst[291:292]\n",
    "    print(len(lst))\n",
    "    parsed_df = parse(lst)\n",
    "    print(parsed_df.shape)\n",
    "    parsed_df.to_csv('./drug_add_291.csv')\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5e3bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --force-reinstall pandas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
